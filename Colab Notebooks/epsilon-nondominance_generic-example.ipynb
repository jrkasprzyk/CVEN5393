{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jrkasprzyk/CVEN5393/blob/main/epsilon_nondominance_from_file.ipynb)\n",
        "\n",
        "*This notebook is part of course notes for CVEN 5393: Water Resource Systems and Management, by Prof. Joseph Kasprzyk at CU Boulder.*\n",
        "\n",
        "In this notebook, we will perform epsilon non-dominated sorting of solutions in a text file, using the Platypus Python library.\n",
        "\n",
        "TODO: Upload an example text file. Right now this is hard-coded for the CRB problem"
      ],
      "metadata": {
        "id": "1FQHWkjjOW-C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M4csQ5xeC8-",
        "outputId": "8fbde122-b054-4853-e1bd-0eff317b2040"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: platypus-opt in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from platypus-opt) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install platypus-opt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from platypus import *\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-R6Jjx9zeqkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Archive.txt` is output from BorgRW in 'readable' format. In Colab, you must upload a new copy of the file every time you start a runtime!\n",
        "\n",
        "Here we start with a dataframe of all solutions, `all_solutions_df` and create a column for the label, which will be `True` in case that a solution here ends up being epsilon nondominated. Some benefits of doing this:\n",
        "\n",
        "\n",
        "\n",
        "*   Epsilon non-domination is a nonlinear process. If a new solution is found that epsilon-dominates multiple solutions, it could **delete multiple previous epsilon non-dominated solutions**.\n",
        "*   Therefore assigning labels **at the end of the process** ensures you're not falsely thinking a solution is epsilon non-dominated because it was in the archive early in the analysis!\n",
        "*   Saving the output as labels in the original dataset is useful because you can create **multiple labels** -- for example, you could determine if a solution lived in multiple sorts (different values of epsilon, different subsets of objectives, etc.)"
      ],
      "metadata": {
        "id": "kEymDGCG7sjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import archive (in 'readable' format)\n",
        "all_solutions_df = pd.read_csv(\"Archive.txt\", delimiter=\" \")\n",
        "all_solutions_df[\"Eps Nd\"] = False"
      ],
      "metadata": {
        "id": "rT_dkKske7ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll index the dataframes using a list of the objective names. This allows us to only use a subset of columns for the activities like epsilon non-dominated sorting (since all we're after is a label anyway). When analyzing the data, we will always take the entire row, so other information such as decision variables, metrics, and constraint violations are preserved."
      ],
      "metadata": {
        "id": "jcQ_HslW9Cfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "objective_names = [\"Objectives.Objective_Powell_3490\",\n",
        "                   \"Objectives.Objective_Mead_1000\",\n",
        "                   \"Objectives.Objective_LB_Shortage_Volume\",\n",
        "                   \"Objectives.Objective_Max_Delta_Annual_Shortage\"]\n",
        "num_objs = len(objective_names)\n",
        "\n",
        "epsilons = [5,\n",
        "            1,\n",
        "            10000,\n",
        "            10000]\n",
        "\n",
        "# create a Platypus Problem object. Right now, the Platypus analysis only\n",
        "# uses objectives, so that's all I'm populating. But future analyses may\n",
        "# need to copy other information too\n",
        "problem = Problem(nvars=0, nobjs=num_objs, nconstrs=0)\n",
        "\n",
        "# pt stands for platypus format: these two items will be\n",
        "# lists of Platypus Solution objects. One for all the solutions\n",
        "# and another for only the epsilon non-dominated solutions\n",
        "all_solutions_pt = []\n",
        "eps_solutions_pt = EpsilonBoxArchive(epsilons)\n",
        "\n",
        "# go through all the solutions, and continually update\n",
        "# the epsilon archive. Note that as you go along, the\n",
        "# archive might grow or shrink\n",
        "for index, row in all_solutions_df.iterrows():\n",
        "\n",
        "  # create solution object\n",
        "  solution = Solution(problem)\n",
        "\n",
        "  # save an id for which row of the original\n",
        "  # dataframe this solution came from. really important\n",
        "  # for cross-referencing things later!\n",
        "  solution.id = index\n",
        "\n",
        "  for j in range(num_objs):\n",
        "    solution.objectives[j] = row[objective_names[j]]\n",
        "\n",
        "  # save every solution you look at\n",
        "  all_solutions_pt.append(solution)\n",
        "\n",
        "  # calling the 'add' function on an EpsilonBoxArchive\n",
        "  # orchestrates the archive update algorithm: it only\n",
        "  # puts a solution into the archive if it's epsilon non-dominated\n",
        "  # (and subsequently deletes solutions that end up being dominated!)\n",
        "  eps_solutions_pt.add(solution)"
      ],
      "metadata": {
        "id": "IzXcn9dZfWAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the above is completed, you now have a list of Platypus objects for all solutions: `all_solutions_pt`, which we're not really using here; and `eps_solutions_pt`, a Platypus `EpsilonBoxArchive` which is really just a list of Platypus `Solution` that are guaranteed to be epsilon non-dominated.\n",
        "\n",
        "The last cell here pulls out the solution ids for the epsilon archive and populates labels in the original dataframe that indicate whether a solution is epsilon nondominated. It also creates a new dataframe that only contains the epsilon solutions, for completeness."
      ],
      "metadata": {
        "id": "U4B-wBG2-RuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save a list of the ids of the epsilon non-dominated solutions\n",
        "eps_ids = [sol.id for sol in eps_solutions_pt]\n",
        "\n",
        "# earlier, we initiated this flag to be False. We set it to True\n",
        "# if the solution's id matches the one in the list\n",
        "for id in eps_ids:\n",
        "  all_solutions_df.at[id, \"Eps Nd\"] = True\n",
        "\n",
        "# create a new dataframe that only contains the rows that were\n",
        "# epsilon non-dominated\n",
        "eps_solutions_df = all_solutions_df[all_solutions_df[\"Eps Nd\"]].copy(deep=True)"
      ],
      "metadata": {
        "id": "97Mtp6fu41kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By converting all of our work into a label for the original dataset, it helps facilitate lots of different experiments on that dataset. In other words, you can see which of the ‘original’ solutions survived the test. This is especially helpful when you have multiple ‘tests’ you’re performing on your solutions. For example, imagine that you had labels that indicated that a given row of the big dataframe came from a given optimization experiment .. then you could do lots of interesting things like show which ones are epsilon non-dominated across all experiments, within one experiment, etc. You just repeat the same procedure just assigning different labels to the original set."
      ],
      "metadata": {
        "id": "GRyiaJZjDpQl"
      }
    }
  ]
}